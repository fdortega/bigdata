{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Dask\n",
    "\n",
    "1. In this task, you'll train several machine-learning models from scikit-learn, using Dask as the backend of joblib. This time, you need to use all of the variables except Class as your feature set. The Class variable will be your target variable.\n",
    "\n",
    "2. Compare the results of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "from dask.distributed import Client, progress\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:54473</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>8.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:54473' processes=4 threads=8, memory=8.00 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Client setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "client = Client(n_workers=4, threads_per_worker=2, memory_limit='2GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credit card fraud dataset (File stored locally)\n",
    "df = dd.read_csv(r'C:\\Users\\felix\\Downloads\\archive (1)\\creditcard.csv', dtype={'Time': 'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install dask-ml and import train_test_split\n",
    "!pip install dask-ml\n",
    "from dask_ml.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=3\n",
       "    int64\n",
       "      ...\n",
       "      ...\n",
       "      ...\n",
       "Name: Class, dtype: int64\n",
       "Dask Name: split, 3 tasks"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our feature set\n",
    "X = df.drop(columns = ['Class'])\n",
    "\n",
    "# This is our target variable\n",
    "Y = df[\"Class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# Since our data can fit into memory\n",
    "# we persist them to the RAM.\n",
    "X_train.persist()\n",
    "X_test.persist()\n",
    "y_train.persist()\n",
    "y_test.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([146.0893867 , 144.20853758, 145.42736745, 139.58098388]),\n",
       " 'score_time': array([0.13609958, 0.26554942, 0.23430848, 0.56800294]),\n",
       " 'test_score': array([0.02029621, 0.99949172, 0.99942161, 0.99931644])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Use parallelization to cross validate\n",
    "with joblib.parallel_backend('dask'):\n",
    "    scores = cross_validate(rf_model, X_train.compute(), y_train.compute(), cv=4)\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search parameter\n",
    "rf_params = {\"max_depth\": [2, 4, 8, 16]}\n",
    "\n",
    "# Instantiate model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# run grid search\n",
    "grid_search_rf = GridSearchCV(rf_model,\n",
    "                           param_grid=rf_params,\n",
    "                           return_train_score=True,\n",
    "                           iid=True,\n",
    "                           cv=2,\n",
    "                           scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with training data\n",
    "with joblib.parallel_backend('dask'):\n",
    "    grid_search_rf.fit(X_train.compute(), y_train.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value is:  {'max_depth': 4}\n",
      "The test AUC score is:  0.9529803879110763\n"
     ]
    }
   ],
   "source": [
    "print(\"The best value is: \", grid_search_rf.best_params_)\n",
    "print(\"The test AUC score is: \", grid_search_rf.score(X_test.compute(), y_test.compute()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a logistice regression model and train\n",
    "lr = LogisticRegression()\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    lr.fit(X_train.values.compute(), y_train.values.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is:  0.9371863195855031\n",
      "Test score is:  0.9503862509341974\n"
     ]
    }
   ],
   "source": [
    "# Obtain scores for both train and test\n",
    "preds_train = lr.predict(X_train.values.compute())\n",
    "preds_test = lr.predict(X_test.values.compute())\n",
    "\n",
    "print(\"Training score is: \", roc_auc_score(preds_train, y_train.values.compute()))\n",
    "print(\"Test score is: \", roc_auc_score(preds_test, y_test.values.compute()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search parameter\n",
    "xgboost_params = {\"n_estimators\": [5, 10, 20]}\n",
    "\n",
    "# Instantiate XGBoost Classifier Model\n",
    "xgboost = GradientBoostingClassifier()\n",
    "\n",
    "# run grid search\n",
    "grid_search_xgb = GridSearchCV(xgboost, param_grid = xgboost_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with training data\n",
    "with joblib.parallel_backend('dask'):\n",
    "    grid_search_xgb.fit(X_train.compute(), y_train.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator is:  {'n_estimators': 10}\n",
      "The test AUC score is:  0.9991164204424966\n"
     ]
    }
   ],
   "source": [
    "print(\"The best estimator is: \", grid_search_xgb.best_params_)\n",
    "print(\"The test AUC score is: \", grid_search_xgb.score(X_test.compute(), y_test.compute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost classifier has the best test score using all standard parameters with the exception of the number of estimators."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
